{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要なライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchinfo import summary\n",
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('*.csv') \n",
    "def getfile(datas, name): \n",
    "    return [data for data in datas if name in data][0] \n",
    "path_digits_train, path_digits_test, path_digits_sample = getfile(files, 'train'), getfile(files, 'test'), getfile(files, 'sample') \n",
    "df_digits_train, df_digits_test, df_digits_sample = pd.read_csv(path_digits_train), pd.read_csv(path_digits_test), pd.read_csv(path_digits_sample) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0    785\n",
      "Name: count, dtype: int64\n",
      "test: 0    784\n",
      "Name: count, dtype: int64\n",
      "sample: 0    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missvalues_train = df_digits_train.isnull().sum()\n",
    "missvalues_test = df_digits_test.isnull().sum()\n",
    "missvalues_sample = df_digits_sample.isnull().sum()\n",
    "print('train:', missvalues_train.value_counts())\n",
    "print('test:', missvalues_test.value_counts())\n",
    "print('sample:', missvalues_sample.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データとラベルの分割(データはNumpy型データに変換、その後正規化する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train, df_y_train = df_digits_train.drop(columns=['label']), df_digits_train['label'] \n",
    "x_train_linear, y_train_linear = df_x_train.to_numpy(), df_y_train.to_numpy() \n",
    "x_train_linear = x_train_linear/255 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の形状操作、形状確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28) (42000,) MinMax: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_np, y_train_np = x_train_linear.reshape(-1, 28, 28), y_train_linear\n",
    "print(x_train_np.shape, y_train_np.shape, 'MinMax:', x_train_np.min(), x_train_np.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorchを使用するための前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42000, 1, 28, 28]) torch.Size([42000])\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.tensor(x_train_np, dtype = torch.float32)\n",
    "x_train_tensor = x_train_tensor.unsqueeze(1)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype = torch.int64)\n",
    "print(x_train_tensor.shape, y_train_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:torch.Size([33600, 1, 28, 28]), y_train:torch.Size([33600]), x_val:torch.Size([8400, 1, 28, 28]), y_val:torch.Size([8400])\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_tensor, y_train_tensor, test_size = 0.2, random_state = 0)\n",
    "print(f'x_train:{x_train.shape}, y_train:{y_train.shape}, x_val:{x_val.shape}, y_val:{y_val.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの作成(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1) #(in_C, out_C, kernel_size, stride)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) #outputsize(h, w, c) = (14, 14, 16)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) #outputsize(h, w, c) = (7, 7, 32)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(32*7*7, 256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.conv1(x))\n",
    "        out = self.relu2(self.conv2(out))\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        out = self.relu3(self.conv3(out))\n",
    "        out = self.relu4(self.conv4(out))\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.relu5(self.linear1(out))\n",
    "        out = self.dropout1(out)\n",
    "        out = self.linear2(out)\n",
    "        return out "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構造の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Conv2d: 1-1                            160\n",
       "├─ReLU: 1-2                              --\n",
       "├─Conv2d: 1-3                            2,320\n",
       "├─ReLU: 1-4                              --\n",
       "├─MaxPool2d: 1-5                         --\n",
       "├─Conv2d: 1-6                            4,640\n",
       "├─ReLU: 1-7                              --\n",
       "├─Conv2d: 1-8                            9,248\n",
       "├─ReLU: 1-9                              --\n",
       "├─MaxPool2d: 1-10                        --\n",
       "├─AdaptiveAvgPool2d: 1-11                --\n",
       "├─Flatten: 1-12                          --\n",
       "├─Linear: 1-13                           401,664\n",
       "├─ReLU: 1-14                             --\n",
       "├─Dropout: 1-15                          --\n",
       "├─Linear: 1-16                           2,570\n",
       "=================================================================\n",
       "Total params: 420,602\n",
       "Trainable params: 420,602\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Net())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータの確定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.001\n",
    "\n",
    "def logging_epoch(logs, epoch, loss, accuracy):  \n",
    "    logs['epoch'].append(epoch) \n",
    "    logs['loss'].append(loss) \n",
    "    logs['accuracy'].append(accuracy) \n",
    "\n",
    "logs = {'train':{'epoch':[], 'loss':[], 'accuracy':[]},\n",
    "        'val':{'epoch':[], 'loss':[], 'accuracy':[]}} \n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss() #損失関数の設定：クロスエントロピー誤差"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ログの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logs(logs):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    #損失関数のグラフ化\n",
    "    ax[0].plot(logs['train']['epoch'], logs['train']['loss'], label='train', ls='--') #train\n",
    "    ax[0].plot(logs['val']['epoch'], logs['val']['loss'], label='val') #val\n",
    "    ax[0].set_xlabel('epoch')\n",
    "    ax[0].set_ylabel('loss')\n",
    "    ax[0].set_title('Time series of Loss')\n",
    "    ax[0].legend(), ax[0].grid()\n",
    "    #正解率のグラフ化\n",
    "    ax[1].plot(logs['train']['epoch'], logs['train']['accuracy'], label='train', ls='--') #train\n",
    "    ax[1].plot(logs['val']['epoch'], logs['val']['accuracy'], label='val') #val\n",
    "    ax[1].set_xlabel('epoch')\n",
    "    ax[1].set_ylabel('accuracy')\n",
    "    ax[1].set_title('Time series of Accuracy')\n",
    "    ax[1].legend(), ax[1].grid()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUへの転送&バッチ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x_train, x_val, y_train, y_val = x_train.to(device), x_val.to(device), y_train.to(device), y_val.to(device) \n",
    "\n",
    "x_train_minibatch = DataLoader(x_train, batch_size=60, shuffle=False)\n",
    "y_train_minibatch = DataLoader(y_train, batch_size=60, shuffle=False)\n",
    "x_val_minibatch = DataLoader(x_val, batch_size=60, shuffle=False)\n",
    "y_val_minibatch = DataLoader(y_val, batch_size=60, shuffle=False)\n",
    "\n",
    "net= net.to(device) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss, train_acc  = 0, 0\n",
    "    val_loss, val_acc  = 0, 0\n",
    "    \n",
    "    #訓練フェーズ\n",
    "    net.train()\n",
    "    count = 0\n",
    "    \n",
    "    for imgs, labels in zip(x_train_minibatch, y_train_minibatch):\n",
    "        count += len(labels) \n",
    "        print(f'epoch: {epoch}, count: {count}, len(labels): {len(labels)}')\n",
    "        \n",
    "        #学習フェーズ\n",
    "        optimizer.zero_grad() #勾配の初期化\n",
    "        outputs = net(imgs) #順伝播(出力の計算)\n",
    "        loss = criterion(outputs, labels) #損失関数の計算\n",
    "        loss.backward()\n",
    "        optimizer.step() #パラメータ更新\n",
    "        \n",
    "        #ロギングデータの更新\n",
    "        train_loss += loss.item() #損失関数の合計を計算\n",
    "        y_pred = torch.max(outputs, 1)[1]\n",
    "        train_acc += (y_pred == labels).sum().item() #正解数を計算\n",
    "        \n",
    "        loss_train_avg = train_loss / count #損失関数の平均を計算\n",
    "        loss_acc_avg = train_acc / count #正解率の平均を計算\n",
    "    \n",
    "    #検証フェーズ\n",
    "    net.eval()\n",
    "    count = 0\n",
    "    \n",
    "    for imgs, labels in zip(x_val_minibatch, y_val_minibatch):\n",
    "        count += len(labels) #データ数をカウント\n",
    "\n",
    "        #推論フェーズ\n",
    "        outputs = net(imgs) #順伝播(出力の計算)\n",
    "        loss = criterion(outputs, labels) #損失関数の計算\n",
    "\n",
    "        #ロギングデータの更新\n",
    "        val_loss += loss.item() #損失関数の合計を計算\n",
    "        y_pred = torch.max(outputs, 1)[1]\n",
    "        val_acc += (y_pred == labels).sum().item() #正解数を計算\n",
    "\n",
    "        loss_val_avg = val_loss / count #損失関数の平均を計算\n",
    "        loss_acc_avg = val_acc / count #正解率の平均を計算\n",
    "    \n",
    "    #学習結果の表示/ロギング\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch}, loss_train: {loss_train_avg:.4f}, loss_val: {loss_val_avg:.4f}, acc_train: {loss_acc_avg:.4f}, acc_val: {loss_acc_avg:.4f}')\n",
    "        logging_epoch(logs['train'], epoch=epoch, loss=loss_train_avg, accuracy=loss_acc_avg)\n",
    "        logging_epoch(logs['val'], epoch=epoch, loss=loss_val_avg, accuracy=loss_acc_avg)\n",
    "    \n",
    "plot_logs(logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/params_CNN.pth') \n",
    "joblib.dump(logs, 'logs_digits_lr0.01_batch.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習済みモデルの呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "# モデルのパラメータをロード\n",
    "model_params = torch.load('model_CNNdigits_lr0.01_batch.pth', map_location=torch.device('cpu')) \n",
    "net.load_state_dict(model_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用データへの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([28000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "columns = df_digits_sample.columns\n",
    "\n",
    "x_test_linear = df_digits_test.to_numpy() \n",
    "x_test_linear = x_test_linear/255 \n",
    "x_test_np = x_test_linear.reshape(-1, 28, 28) \n",
    "x_test_tensor = torch.tensor(x_test_np, dtype=torch.float32) \n",
    "x_test = x_test_tensor.unsqueeze(1) #チャネル数を1にする\n",
    "print(type(x_test), x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測＆結果のCSVファイル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = net(x_test) \n",
    "predicted_test = torch.max(outputs, 1)[1] \n",
    "\n",
    "pred = [i.item() for i in predicted_test]\n",
    "df = pd.DataFrame([np.arange(1, len(pred)+1), pred]).T\n",
    "df.columns = columns\n",
    "display(df.head(3))\n",
    "df.to_csv('digitsrecog_lr0.01batch.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
